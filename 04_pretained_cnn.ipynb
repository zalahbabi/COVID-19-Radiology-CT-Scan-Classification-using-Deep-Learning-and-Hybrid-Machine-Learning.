{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e345f2",
   "metadata": {},
   "source": [
    "# Section 04 — Pretrained CNN Models (Transfer Learning)\n",
    "\n",
    "This section fine-tunes the following pretrained architectures:\n",
    "- ResNet50\n",
    "- DenseNet121\n",
    "- VGG16\n",
    "\n",
    "Since CT scans are grayscale, the first convolution layer is modified to accept 1-channel input.\n",
    "\n",
    "We freeze all backbone layers except the final block to reduce training cost and risk of overfitting.  \n",
    "The classification head is replaced with a new fully connected layer for four output classes.\n",
    "\n",
    "Training uses two learning rates:\n",
    "- A higher learning rate for the classifier head\n",
    "- A lower learning rate for the unfrozen backbone layers\n",
    "\n",
    "All models are trained for 15 epochs with best-model checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34dea0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Loaded train + validation datasets.\n",
      "Classes: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Training transforms (with augmentation)\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.10, contrast=0.10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Validation transforms (no augmentation)\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\n",
    "val_dataset   = datasets.ImageFolder(\"data/validation\", transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"✔ Loaded train + validation datasets.\")\n",
    "print(\"Classes:\", class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e921af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for pretrained models with partial fine-tuning\n",
    "def train_pretrained_model(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    num_epochs=15,\n",
    "    lr_classifier=0.001,\n",
    "    lr_backbone=0.0001,\n",
    "    model_name=\"Model\",\n",
    "    save_path=\"model_best.pth\"\n",
    "):\n",
    "\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Two learning rates:\n",
    "    optimizer = torch.optim.Adam([\n",
    "        {\"params\": model.classifier_params, \"lr\": lr_classifier},\n",
    "        {\"params\": model.backbone_params, \"lr\": lr_backbone},\n",
    "    ])\n",
    "\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    print(f\"\\n===== Training {model_name} (Partial Fine-Tuning) =====\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                preds = model(images).argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "\n",
    "        val_acc = correct / total\n",
    "\n",
    "        print(f\"Epoch {epoch}/{num_epochs} | \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"✔ Best model saved → {save_path}\")\n",
    "\n",
    "    print(f\"\\nTraining completed for {model_name}\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b1ee65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ VGG16 ready (Block 5 unfrozen).\n",
      "✔ DenseNet121 ready (last dense block unfrozen).\n",
      "✔ ResNet50 ready (last block unfrozen).\n"
     ]
    }
   ],
   "source": [
    "# Building pretrained models with grayscale fix and partial fine-tuning\n",
    "def build_resnet50(num_classes):\n",
    "    model = models.resnet50(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "    # Fix grayscale 1-channel input\n",
    "    old_weights = model.conv1.weight.data\n",
    "    model.conv1 = nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "    model.conv1.weight.data = old_weights.mean(dim=1, keepdim=True)\n",
    "\n",
    "    # Freeze everything\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze LAST block (partial fine-tune)\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Replace final FC\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    model.classifier_params = model.fc.parameters()\n",
    "    model.backbone_params = model.layer4.parameters()\n",
    "\n",
    "    return model\n",
    "resnet_model = build_resnet50(num_classes)\n",
    "\n",
    "\n",
    "def build_densenet121(num_classes):\n",
    "    model = models.densenet121(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "    # Fix 1-channel input\n",
    "    old_weights = model.features.conv0.weight.data\n",
    "    model.features.conv0 = nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
    "    model.features.conv0.weight.data = old_weights.mean(dim=1, keepdim=True)\n",
    "\n",
    "    # Freeze ALL layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze LAST DenseBlock\n",
    "    for param in model.features.denseblock4.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Replace classifier\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "\n",
    "    model.classifier_params = model.classifier.parameters()\n",
    "    model.backbone_params = model.features.denseblock4.parameters()\n",
    "\n",
    "    return model\n",
    "densenet_model = build_densenet121(num_classes)\n",
    "\n",
    "\n",
    "def build_vgg16(num_classes):\n",
    "    model = models.vgg16(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "    # Fix grayscale input\n",
    "    old_weights = model.features[0].weight.data\n",
    "    model.features[0] = nn.Conv2d(1, 64, 3, padding=1)\n",
    "    model.features[0].weight.data = old_weights.mean(dim=1, keepdim=True)\n",
    "\n",
    "    # Freeze ALL conv layers\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Unfreeze LAST conv block (Block 5)\n",
    "    for param in model.features[24:].parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Replace classifier\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    model.classifier_params = model.classifier.parameters()\n",
    "    model.backbone_params = model.features[24:].parameters()\n",
    "\n",
    "    return model\n",
    "vgg_model = build_vgg16(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbaaf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Training ResNet50 (Partial Fine-Tuning) =====\n",
      "Epoch 1/15 | Train Loss: 0.3777 | Val Acc: 0.9172\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 2/15 | Train Loss: 0.2393 | Val Acc: 0.9291\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 3/15 | Train Loss: 0.2118 | Val Acc: 0.9169\n",
      "Epoch 4/15 | Train Loss: 0.1835 | Val Acc: 0.9317\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 5/15 | Train Loss: 0.1665 | Val Acc: 0.9326\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 6/15 | Train Loss: 0.1565 | Val Acc: 0.9348\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 7/15 | Train Loss: 0.1434 | Val Acc: 0.9235\n",
      "Epoch 8/15 | Train Loss: 0.1382 | Val Acc: 0.9272\n",
      "Epoch 9/15 | Train Loss: 0.1333 | Val Acc: 0.9364\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 10/15 | Train Loss: 0.1144 | Val Acc: 0.9357\n",
      "Epoch 11/15 | Train Loss: 0.1096 | Val Acc: 0.9257\n",
      "Epoch 12/15 | Train Loss: 0.1098 | Val Acc: 0.9380\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 13/15 | Train Loss: 0.0999 | Val Acc: 0.9493\n",
      "✔ Best model saved → models/resnet50_model.pth\n",
      "Epoch 14/15 | Train Loss: 0.0905 | Val Acc: 0.9471\n",
      "Epoch 15/15 | Train Loss: 0.0876 | Val Acc: 0.9483\n",
      "\n",
      "Training completed for ResNet50\n",
      "Best Validation Accuracy: 0.9493\n",
      "\n",
      "===== Training DenseNet121 (Partial Fine-Tuning) =====\n",
      "Epoch 1/15 | Train Loss: 0.4362 | Val Acc: 0.8750\n",
      "✔ Best model saved → models/densenet121_model.pth\n",
      "Epoch 2/15 | Train Loss: 0.2880 | Val Acc: 0.9014\n",
      "✔ Best model saved → models/densenet121_model.pth\n",
      "Epoch 3/15 | Train Loss: 0.2351 | Val Acc: 0.9146\n",
      "✔ Best model saved → models/densenet121_model.pth\n",
      "Epoch 4/15 | Train Loss: 0.2208 | Val Acc: 0.9244\n",
      "✔ Best model saved → models/densenet121_model.pth\n",
      "Epoch 5/15 | Train Loss: 0.1981 | Val Acc: 0.9351\n",
      "✔ Best model saved → models/densenet121_model.pth\n",
      "Epoch 6/15 | Train Loss: 0.1806 | Val Acc: 0.9102\n",
      "Epoch 7/15 | Train Loss: 0.1596 | Val Acc: 0.9317\n",
      "Epoch 8/15 | Train Loss: 0.1525 | Val Acc: 0.9008\n",
      "Epoch 9/15 | Train Loss: 0.1416 | Val Acc: 0.9263\n",
      "Epoch 10/15 | Train Loss: 0.1389 | Val Acc: 0.9225\n",
      "Epoch 11/15 | Train Loss: 0.1212 | Val Acc: 0.9307\n",
      "Epoch 12/15 | Train Loss: 0.1247 | Val Acc: 0.9298\n",
      "Epoch 13/15 | Train Loss: 0.1128 | Val Acc: 0.9162\n",
      "Epoch 14/15 | Train Loss: 0.1140 | Val Acc: 0.9291\n",
      "Epoch 15/15 | Train Loss: 0.1060 | Val Acc: 0.9269\n",
      "\n",
      "Training completed for DenseNet121\n",
      "Best Validation Accuracy: 0.9351\n",
      "\n",
      "===== Training VGG16 (Partial Fine-Tuning) =====\n",
      "Epoch 1/15 | Train Loss: 0.6274 | Val Acc: 0.8189\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 2/15 | Train Loss: 0.4130 | Val Acc: 0.8882\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 3/15 | Train Loss: 0.3631 | Val Acc: 0.8825\n",
      "Epoch 4/15 | Train Loss: 0.3104 | Val Acc: 0.8838\n",
      "Epoch 5/15 | Train Loss: 0.2900 | Val Acc: 0.9036\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 6/15 | Train Loss: 0.2704 | Val Acc: 0.9096\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 7/15 | Train Loss: 0.2472 | Val Acc: 0.8910\n",
      "Epoch 8/15 | Train Loss: 0.2440 | Val Acc: 0.9191\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 9/15 | Train Loss: 0.2272 | Val Acc: 0.8775\n",
      "Epoch 10/15 | Train Loss: 0.2275 | Val Acc: 0.9030\n",
      "Epoch 11/15 | Train Loss: 0.2152 | Val Acc: 0.9140\n",
      "Epoch 12/15 | Train Loss: 0.2063 | Val Acc: 0.9137\n",
      "Epoch 13/15 | Train Loss: 0.1955 | Val Acc: 0.9203\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 14/15 | Train Loss: 0.1894 | Val Acc: 0.9228\n",
      "✔ Best model saved → models/vgg16_model.pth\n",
      "Epoch 15/15 | Train Loss: 0.1877 | Val Acc: 0.9184\n",
      "\n",
      "Training completed for VGG16\n",
      "Best Validation Accuracy: 0.9228\n"
     ]
    }
   ],
   "source": [
    "# Training the pretrained models with partial fine-tuning\n",
    "trained_resnet50 = train_pretrained_model(\n",
    "    model=resnet_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=15,\n",
    "    lr_classifier=0.001,\n",
    "    lr_backbone=0.0001,\n",
    "    model_name=\"ResNet50\",\n",
    "    save_path=\"models/resnet50_model.pth\"\n",
    ")\n",
    "\n",
    "trained_densenet121 = train_pretrained_model(\n",
    "    model=densenet_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=15,\n",
    "    lr_classifier=0.001,\n",
    "    lr_backbone=0.0001,\n",
    "    model_name=\"DenseNet121\",\n",
    "    save_path=\"models/densenet121_model.pth\"\n",
    ")\n",
    "\n",
    "trained_vgg16 = train_pretrained_model(\n",
    "    model=vgg_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=15,\n",
    "    lr_classifier=0.001,\n",
    "    lr_backbone=0.0001,\n",
    "    model_name=\"VGG16\",\n",
    "    save_path=\"models/vgg16_model.pth\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
