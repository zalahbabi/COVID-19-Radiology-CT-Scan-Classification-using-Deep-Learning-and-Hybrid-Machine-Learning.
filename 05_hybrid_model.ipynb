{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5f01b7e",
   "metadata": {},
   "source": [
    "# Section 05 â€” Hybrid ML Using Pretrained CNN Features\n",
    "\n",
    "This section uses the best pretrained CNN (ResNet50) as a deep feature extractor.\n",
    "\n",
    "We remove the final classification layer and extract a 2048-dimensional feature vector for each CT scan.  \n",
    "These features are used to train classical machine learning models:\n",
    "\n",
    "- Logistic Regression\n",
    "- KNN\n",
    "- Random Forest\n",
    "\n",
    "Hybrid models often train faster and allow easier interpretability compared to end-to-end deep learning.\n",
    "\n",
    "Feature extraction is performed for train, validation, and test sets.  \n",
    "Each ML model is trained on extracted features and evaluated using the same metrics as the CNN models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4158e315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs(\"models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b1f537",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Train data loaders with augmentations\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# Validation data loaders without augmentations\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"data/train\", transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(\"data/validation\",   transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,   batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d636f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNModel(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    # Define forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "# Load the best saved model\n",
    "best_model = CNNModel(num_classes=4)\n",
    "best_model.load_state_dict(torch.load(\"models/cnn_model.pth\", weights_only=True))\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25766094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor using the trained CNN\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, trained_model):\n",
    "        super().__init__()\n",
    "        self.conv1 = trained_model.conv1\n",
    "        self.conv2 = trained_model.conv2\n",
    "        self.conv3 = trained_model.conv3\n",
    "        self.pool  = trained_model.pool\n",
    "        self.fc1   = trained_model.fc1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        return x\n",
    "    \n",
    "def extract_features(model, dataloader):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    all_X, all_y = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            feats = model(images)      # (B, 512)\n",
    "            all_X.append(feats.cpu().numpy())\n",
    "            all_y.append(labels.numpy())\n",
    "\n",
    "    return np.vstack(all_X), np.hstack(all_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b3cb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train hybrid models\n",
    "def train_hybrid(best_model, train_loader, val_loader):\n",
    "    extractor = CNNFeatureExtractor(best_model)\n",
    "\n",
    "    print(\"Extracting CNN feature vectors...\")\n",
    "    X_train, y_train = extract_features(extractor, train_loader)\n",
    "    X_val,   y_val   = extract_features(extractor, val_loader)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    # random forest\n",
    "    rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    val_acc = accuracy_score(y_val, rf.predict(X_val))\n",
    "    print(\"\\n[RF] Validation Accuracy:\", val_acc)\n",
    "    results[\"RF\"] = val_acc\n",
    "\n",
    "    with open(\"models/rf_hybrid.pkl\", \"wb\") as f:\n",
    "        pickle.dump(rf, f)\n",
    "\n",
    "    # logistic regression\n",
    "    scaler_lr = StandardScaler()\n",
    "    X_train_lr = scaler_lr.fit_transform(X_train)\n",
    "    X_val_lr   = scaler_lr.transform(X_val)\n",
    "\n",
    "    lr = LogisticRegression(max_iter=2000)\n",
    "    lr.fit(X_train_lr, y_train)\n",
    "\n",
    "    val_acc = accuracy_score(y_val, lr.predict(X_val_lr))\n",
    "    print(\"[LR] Validation Accuracy:\", val_acc)\n",
    "    results[\"LR\"] = val_acc\n",
    "\n",
    "    with open(\"models/lr_hybrid.pkl\", \"wb\") as f:\n",
    "        pickle.dump(lr, f)\n",
    "    with open(\"models/lr_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler_lr, f)\n",
    "\n",
    "    # k-nearest neighbors\n",
    "    scaler_knn = StandardScaler()\n",
    "    X_train_knn = scaler_knn.fit_transform(X_train)\n",
    "    X_val_knn   = scaler_knn.transform(X_val)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train_knn, y_train)\n",
    "\n",
    "    val_acc = accuracy_score(y_val, knn.predict(X_val_knn))\n",
    "    print(\"[KNN] Validation Accuracy:\", val_acc)\n",
    "    results[\"KNN\"] = val_acc\n",
    "\n",
    "    with open(\"models/knn_hybrid.pkl\", \"wb\") as f:\n",
    "        pickle.dump(knn, f)\n",
    "    with open(\"models/knn_scaler.pkl\", \"wb\") as f:\n",
    "        pickle.dump(scaler_knn, f)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e0e169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting CNN feature vectors...\n",
      "\n",
      "[RF] Validation Accuracy: 0.888503937007874\n",
      "[LR] Validation Accuracy: 0.8869291338582678\n",
      "[KNN] Validation Accuracy: 0.8692913385826772\n",
      "\n",
      "Hybrid Validation Accuracies:\n",
      "{'RF': 0.888503937007874, 'LR': 0.8869291338582678, 'KNN': 0.8692913385826772}\n"
     ]
    }
   ],
   "source": [
    "hybrid_results = train_hybrid(\n",
    "    best_model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader\n",
    ")\n",
    "\n",
    "print(\"\\nHybrid Validation Accuracies:\")\n",
    "print(hybrid_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
