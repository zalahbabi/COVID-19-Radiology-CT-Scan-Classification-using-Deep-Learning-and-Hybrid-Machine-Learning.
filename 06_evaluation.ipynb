{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ffa48f0",
   "metadata": {},
   "source": [
    "# Section 06 — Final Evaluation and Model Comparison\n",
    "\n",
    "This section evaluates all models:\n",
    "\n",
    "1. Custom CNN  \n",
    "2. Fine-tuned ResNet50  \n",
    "3. Fine-tuned DenseNet121  \n",
    "4. Fine-tuned VGG16  \n",
    "5. Hybrid CNN + Logistic Regression  \n",
    "6. Hybrid CNN + KNN  \n",
    "7. Hybrid CNN + Random Forest  \n",
    "\n",
    "Metrics computed:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1-score\n",
    "- Specificity\n",
    "- Confusion Matrix\n",
    "\n",
    "All models are evaluated on the test set using the same pipeline.  \n",
    "A comparison table is produced to summarize performance and identify the strongest method.  \n",
    "This section completes the full machine learning workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2dbf216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "65ae1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Test DataLoader ready\n",
      "Classes: ['COVID', 'Lung_Opacity', 'Normal', 'Viral Pneumonia']\n",
      "Total test samples: 3176\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(\"data/test\", transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "class_names = test_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"✔ Test DataLoader ready\")\n",
    "print(\"Classes:\", class_names)\n",
    "print(\"Total test samples:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdc91b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ ALL CNN models loaded\n"
     ]
    }
   ],
   "source": [
    "# Define CNN model\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Load Custom CNN\n",
    "custom = CNNModel(num_classes=num_classes)\n",
    "state_dict = torch.load(\"models/cnn_model.pth\", weights_only=True)\n",
    "custom.load_state_dict(state_dict)\n",
    "custom.eval()\n",
    "\n",
    "# Load Pretrained Models\n",
    "def load_resnet50():\n",
    "    model = models.resnet50(weights=None)\n",
    "    # Fix conv1 to accept 1-channel (must match training)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    # Replace classifier\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "    # Load trained weights\n",
    "    state = torch.load(\"models/resnet50_model.pth\", map_location=\"cpu\")\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_densenet121():\n",
    "    model = models.densenet121(weights=None)\n",
    "\n",
    "    # Fix input 1-channel\n",
    "    model.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    # Replace classifier\n",
    "    model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "    state = torch.load(\"models/densenet121_model.pth\", map_location=\"cpu\")\n",
    "    model.load_state_dict(state)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_vgg16():\n",
    "    model = models.vgg16(weights=None)\n",
    "\n",
    "    # Fix 1-channel input\n",
    "    model.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    # Replace classifier\n",
    "    model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, num_classes)\n",
    "\n",
    "    state = torch.load(\"models/vgg16_model.pth\", map_location=\"cpu\")\n",
    "    model.load_state_dict(state)\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "print(\"✔ ALL CNN models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a3e31bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate specificity\n",
    "def compute_specificity(cm):\n",
    "    spec_per_class = []\n",
    "    total = cm.sum()\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "        TP = cm[i, i]\n",
    "        FN = cm[i, :].sum() - TP\n",
    "        FP = cm[:, i].sum() - TP\n",
    "        TN = total - (TP + FN + FP)\n",
    "\n",
    "        specificity = TN / (TN + FP + 1e-9)\n",
    "        spec_per_class.append(specificity)\n",
    "\n",
    "    weights = cm.sum(axis=1)\n",
    "    weighted_spec = np.average(spec_per_class, weights=weights)\n",
    "\n",
    "    return spec_per_class, weighted_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb2fd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate CNN model\n",
    "def evaluate_cnn(model, test_loader, name=\"Model\"):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            preds = model(imgs).argmax(1)\n",
    "            y_true.append(labels.cpu().numpy())\n",
    "            y_pred.append(preds.cpu().numpy())\n",
    "\n",
    "    y_true = np.concatenate(y_true)\n",
    "    y_pred = np.concatenate(y_pred)\n",
    "\n",
    "    # METRICS\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    spec_per_class, spec_weighted = compute_specificity(cm)\n",
    "\n",
    "    # SAVE CONFUSION MATRIX\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"{name} — Confusion Matrix\")\n",
    "    plt.savefig(f\"results/confusion_matrices/{name}_cm.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n===== {name} =====\")\n",
    "    print(f\"Accuracy:     {acc:.4f}\")\n",
    "    print(f\"Precision:    {prec:.4f}\")\n",
    "    print(f\"Recall:       {rec:.4f}\")\n",
    "    print(f\"F1 Score:     {f1:.4f}\")\n",
    "    print(f\"Specificity:  {spec_weighted:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"specificity\": spec_weighted,\n",
    "        \"cm\": cm\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fd654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== CustomCNN =====\n",
      "Accuracy:     0.8835\n",
      "Precision:    0.8840\n",
      "Recall:       0.8835\n",
      "F1 Score:     0.8832\n",
      "Specificity:  0.9321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/vlmmkm_1721cqr67q9d1s1mh0000gn/T/ipykernel_9535/314160117.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"models/resnet50_model.pth\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== ResNet50 =====\n",
      "Accuracy:     0.9424\n",
      "Precision:    0.9425\n",
      "Recall:       0.9424\n",
      "F1 Score:     0.9423\n",
      "Specificity:  0.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/vlmmkm_1721cqr67q9d1s1mh0000gn/T/ipykernel_9535/314160117.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"models/densenet121_model.pth\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DenseNet121 =====\n",
      "Accuracy:     0.9254\n",
      "Precision:    0.9254\n",
      "Recall:       0.9254\n",
      "F1 Score:     0.9251\n",
      "Specificity:  0.9514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0y/vlmmkm_1721cqr67q9d1s1mh0000gn/T/ipykernel_9535/314160117.py:73: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(\"models/vgg16_model.pth\", map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== VGG16 =====\n",
      "Accuracy:     0.9229\n",
      "Precision:    0.9236\n",
      "Recall:       0.9229\n",
      "F1 Score:     0.9230\n",
      "Specificity:  0.9520\n",
      "✔ CNN evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "results[\"CustomCNN\"] = evaluate_cnn(custom, test_loader, \"CustomCNN\")\n",
    "results[\"ResNet50\"] = evaluate_cnn(load_resnet50(), test_loader, \"ResNet50\")\n",
    "results[\"DenseNet121\"] = evaluate_cnn(load_densenet121(), test_loader, \"DenseNet121\")\n",
    "results[\"VGG16\"] = evaluate_cnn(load_vgg16(), test_loader, \"VGG16\")\n",
    "\n",
    "print(\"✔ CNN evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e974d2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Hybrid ML models loaded\n"
     ]
    }
   ],
   "source": [
    "with open(\"models/rf_hybrid.pkl\", \"rb\") as f:\n",
    "    rf = pickle.load(f)\n",
    "\n",
    "with open(\"models/lr_hybrid.pkl\", \"rb\") as f:\n",
    "    lr = pickle.load(f)\n",
    "with open(\"models/lr_scaler.pkl\", \"rb\") as f:\n",
    "    lr_scaler = pickle.load(f)\n",
    "\n",
    "with open(\"models/knn_hybrid.pkl\", \"rb\") as f:\n",
    "    knn = pickle.load(f)\n",
    "with open(\"models/knn_scaler.pkl\", \"rb\") as f:\n",
    "    knn_scaler = pickle.load(f)\n",
    "\n",
    "print(\"✔ Hybrid ML models loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe08407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Extracted CNN features for hybrid test evaluation\n"
     ]
    }
   ],
   "source": [
    "# Feature extractor (same as training)\n",
    "class CustomCNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self, trained_model):\n",
    "        super().__init__()\n",
    "        self.conv1 = trained_model.conv1\n",
    "        self.conv2 = trained_model.conv2\n",
    "        self.conv3 = trained_model.conv3\n",
    "        self.pool  = trained_model.pool\n",
    "        self.fc1   = trained_model.fc1\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "extractor = CustomCNNFeatureExtractor(custom)\n",
    "\n",
    "def extract_features(model, dataloader):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    feats, labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for imgs, y in dataloader:\n",
    "            imgs = imgs.to(device)\n",
    "            vec = model(imgs)\n",
    "            feats.append(vec.cpu().numpy())\n",
    "            labels.append(y.numpy())\n",
    "\n",
    "    return np.vstack(feats), np.hstack(labels)\n",
    "\n",
    "X_test, y_test = extract_features(extractor, test_loader)\n",
    "print(\"✔ Extracted CNN features for hybrid test evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3afa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Hybrid RF =====\n",
      "Accuracy:     0.8829\n",
      "Precision:    0.8849\n",
      "Recall:       0.8829\n",
      "F1 Score:     0.8829\n",
      "Specificity:  0.9234\n",
      "\n",
      "===== Hybrid LR =====\n",
      "Accuracy:     0.8816\n",
      "Precision:    0.8820\n",
      "Recall:       0.8816\n",
      "F1 Score:     0.8817\n",
      "Specificity:  0.9278\n",
      "\n",
      "===== Hybrid KNN =====\n",
      "Accuracy:     0.8611\n",
      "Precision:    0.8618\n",
      "Recall:       0.8611\n",
      "F1 Score:     0.8612\n",
      "Specificity:  0.9164\n",
      "✔ Hybrid evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Hybrid Models\n",
    "def evaluate_hybrid_model(name, model, X_test, y_test, scaler=None):\n",
    "\n",
    "    if scaler:\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_test_scaled = X_test\n",
    "\n",
    "    preds = model.predict(X_test_scaled)\n",
    "\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    prec = precision_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, preds, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    spec_per_class, spec_weighted = compute_specificity(cm)\n",
    "\n",
    "    # save cm\n",
    "    plt.figure(figsize=(6,5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Hybrid {name} — Confusion Matrix\")\n",
    "    plt.savefig(f\"results/confusion_matrices/Hybrid_{name}_cm.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n===== Hybrid {name} =====\")\n",
    "    print(f\"Accuracy:     {acc:.4f}\")\n",
    "    print(f\"Precision:    {prec:.4f}\")\n",
    "    print(f\"Recall:       {rec:.4f}\")\n",
    "    print(f\"F1 Score:     {f1:.4f}\")\n",
    "    print(f\"Specificity:  {spec_weighted:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": prec,\n",
    "        \"recall\": rec,\n",
    "        \"f1\": f1,\n",
    "        \"specificity\": spec_weighted,\n",
    "        \"cm\": cm\n",
    "    }\n",
    "\n",
    "results[\"Hybrid_RF\"]  = evaluate_hybrid_model(\"RF\",  rf,  X_test, y_test)\n",
    "results[\"Hybrid_LR\"]  = evaluate_hybrid_model(\"LR\",  lr,  X_test, y_test, lr_scaler)\n",
    "results[\"Hybrid_KNN\"] = evaluate_hybrid_model(\"KNN\", knn, X_test, y_test, knn_scaler)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
